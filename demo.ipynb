{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from model.dali_pipe import dali_generator\n",
    "from model.resnet import Resnet50\n",
    "from model.lars import LARS\n",
    "import horovod.tensorflow as hvd\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvd.init()\n",
    "\n",
    "data_dir = Path('/workspace/shared_workspace/data/imagenet/')\n",
    "index_dir = Path('/workspace/shared_workspace/data/imagenet_index/')\n",
    "train_files = [i.as_posix() for i in data_dir.glob('*1024')]\n",
    "train_index = [i.as_posix() for i in index_dir.glob('*1024')]\n",
    "\n",
    "batch_size = 128\n",
    "image_count = 1282048\n",
    "steps_per_epoch = image_count//batch_size\n",
    "learning_rate = 0.01*batch_size/256\n",
    "scaled_rate = 3.7\n",
    "\n",
    "tf.keras.backend.set_floatx('float16')\n",
    "tf.keras.backend.set_epsilon(1e-4)\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "# mpirun -np 8 -H localhost:8 --bind-to none --allow-run-as-root python transfer_learning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = WarmupExponentialDecay(tf.cast(learning_rate, tf.float16), scaled_rate, steps_per_epoch, steps_per_epoch*10, 0.001)\n",
    "train_tf = dali_generator(train_files, train_index, batch_size)\n",
    "model = Resnet50()\n",
    "optimizer = LARS(scheduler, use_nesterov=False, clip=False)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images, training=True)\n",
    "        loss = loss_func(labels, pred)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for epoch in range(30):\\n    loss = []\\n    progressbar = tqdm(range(steps_per_epoch))\\n    for batch in progressbar:\\n        images, labels = next(train_tf)\\n        loss.append(train_step(images, labels).numpy())\\n        progressbar.set_description(\"train_loss: {0:.4f}\".format(np.array(loss[-100:]).mean()))'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    loss = []\n",
    "    progressbar = tqdm(range(steps_per_epoch))\n",
    "    for batch in progressbar:\n",
    "        images, labels = next(train_tf)\n",
    "        loss.append(train_step(images, labels).numpy())\n",
    "        progressbar.set_description(\"train_loss: {0:.4f}\".format(np.array(loss[-100:]).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
